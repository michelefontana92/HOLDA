<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>HOLDA.buildingBlocks.remote_client_nn API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>HOLDA.buildingBlocks.remote_client_nn</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from buildingBlocks.remote_client import RemoteLocalClient
from utils.data_loaders import create_data_loader
import torch.nn as nn
import torch
from utils.messages import CV_ValidationMessage
from utils.messages import ClientMessage
import datetime
from utils.metrics_sklearn import evaluate_metrics, metrics_to_string
import numpy as np
from metadata.meta import CheckPoint
import pandas as pd
import ray
import copy
import pickle as pkl
import os


@ray.remote(num_cpus=1)
class RemoteLocalClient_NN(RemoteLocalClient):
    &#34;&#34;&#34;
    # Description:

    It represents a Local Client, which trains a Neural Network in a federated way.
    It is a subclass of `RemoteLocalClient`

    &#34;&#34;&#34;

    def __init__(self, metadata, client_hp, dataset_path, test_set_path,
                 train_path=None, val_path=None):
        super().__init__(metadata, client_hp, dataset_path,
                         test_set_path, train_path, val_path)

    def _evaluate_model(self, data_loader, compute_loss=False):
        &#34;&#34;&#34;
        # Description:
        It evaluates the current model, stored in self.model, according to the predefined metrics.

        # Args:

        `data_loader`: (DataLoader)
        Pytorch data loader of the underlying dataset

        `compute_loss`: (bool)
        If True, the function computes the value of the loss.
        If False, the value of the loss returned in output is set to 0.0
        # Returns:
        `(loss, metrics) : (float, dict)`
        The value of the loss function (if computed) and the score for each selected metric.
        &#34;&#34;&#34;
        total_loss = 0.0
        n_batches = 0

        if compute_loss:
            criterion = self.criterion_fn()

        y_true = np.array([])
        y_pred = np.array([])

        with torch.no_grad():
            self.model.eval()
            for i, batch in enumerate(data_loader):
                n_batches += 1
                data = batch[&#39;data&#39;]
                labels = batch[&#39;target&#39;]
                outputs = self.model(data)
                _, predicted = torch.max(torch.log_softmax(outputs, 1), 1)

                y_true = np.append(y_true, labels.flatten().detach().numpy())
                y_pred = np.append(
                    y_pred, predicted.flatten().detach().numpy())

                if compute_loss:
                    loss = criterion(outputs, labels)
                    total_loss += loss.item()

            if compute_loss:
                total_loss = round(total_loss / n_batches, 4)

            metrics = evaluate_metrics(
                self.metadata.metrics, y_true, y_pred)

        del y_true
        del y_pred

        return total_loss, metrics

    def _build_train_and_val_set(self, server_message):
        &#34;&#34;&#34;
        # Description:

        The function builds the training and the validation sets that have to be used during the training process.

        # Args:

        `server_message`: (ServerMessage)
            Message received from the parent node.

        # Returns:

        `(train_set, val_set): (DataFrame, DataFrame)`
        The training and the validation set, respectively


        &#34;&#34;&#34;

        if server_message.validation_msg.from_file:
            train_set = pd.read_csv(self.train_path)
            val_set = pd.read_csv(self.val_path)
        else:
            self.dataset = pd.read_csv(self.dataset_path)

            if len(self.fold_split) == 0:
                self._split_dataset(
                    self.dataset, server_message.validation_msg)

            if isinstance(server_message.validation_msg, CV_ValidationMessage):
                current_fold = server_message.validation_msg.current_fold
                train_set = self.dataset.iloc[self.fold_split[current_fold][0]]
                val_set = self.dataset.iloc[self.fold_split[current_fold][1]]
                with open(self.metadata.log_path, &#39;a&#39;) as f:
                    f.write(
                        f&#39;{datetime.datetime.now()}: &#39;
                        f&#39;KCV: Eseguo la validazione sul fold &#39;
                        f&#39;{current_fold+1}/{len(self.fold_split)}\n&#39;)

            else:
                train_set = self.dataset.iloc[self.fold_split[0][0]]
                val_set = self.dataset.iloc[self.fold_split[0][1]]
        return train_set, val_set

    def broadcast_train_msg(self, server_message):
        &#34;&#34;&#34;
        ## Description:

        It performs the local training of the received model and eventually updates the internal state of the local client.
        It trains the model, starting from the received parameters, up to the given number of epochs.
        The early stopping is employed as stopping condition.
        The function sends back the parameter of the best generalizing model to the parent node, i.e. the parameters stored in the internal state.   

        ## Args:

        `server_message`: (ServerMessage)
        The message received from the parent node.

        ## Returns:

        ### [message: ClientMessage]

        A list with just one element. The message which is transmitted to the parent node, containing the updated model parameters and the number of records in the training and validation set.
        &#34;&#34;&#34;
        with open(self.metadata.log_path, &#39;a&#39;) as f:
            f.write(
                f&#39;\n{datetime.datetime.now()}: &#39;
                f&#39;Arrivato nuovo modello dal server\n&#39;)

        self.model = self.hyperparams.build_model_fn()
        self.send_deltas = server_message.send_deltas
        initial_model_dict = copy.deepcopy(server_message.new_model)
        self.model.load_state_dict(copy.deepcopy(server_message.new_model))

        self.optimizer = self.hyperparams.optimizer_fn(self.model.parameters())

        n_epochs = self.hyperparams.n_local_epochs
        batch_size = self.hyperparams.batch_size

        patience = self.hyperparams.local_patience
        best_val_f1 = -float(&#39;inf&#39;)
        waiting_epochs = 0
        early_stopping = False
        train_set = None
        val_set = None

        train_set, val_set = self._build_train_and_val_set(server_message)

        total_len = 0
        for key, support in self._compute_support(train_set,
                                                  server_message.target_label).items():
            total_len += support
        assert total_len == len(train_set)
        with open(self.metadata.log_path, &#39;a&#39;) as f:
            f.write(
                f&#39;{datetime.datetime.now()}: &#39;
                f&#39;Dimensione del Training set: &#39;
                f&#39;{len(train_set)} &#39;
                f&#39;Dimensione del Validation set: &#39;
                f&#39;{len(val_set)}\n&#39;)

        if self.hyperparams.use_weights:
            class_weights = self._compute_class_weights(
                train_set, server_message.target_label)
            criterion = self.criterion_fn(weight=class_weights)
        else:
            criterion = self.criterion_fn()

        train_loader = create_data_loader(
            train_set, server_message.target_label, batch_size, shuffle=True)

        val_loader = create_data_loader(
            val_set, server_message.target_label, batch_size, shuffle=True)

        epoch = 0

        train_history = {&#39;loss&#39;: [],
                         &#39;precision&#39;: [],
                         &#39;recall&#39;: [],
                         &#39;f1&#39;: [],
                         &#39;accuracy&#39;: []}
        val_history = {&#39;loss&#39;: [],
                       &#39;precision&#39;: [],
                       &#39;recall&#39;: [],
                       &#39;f1&#39;: [],
                       &#39;accuracy&#39;: []}

        best_epoch = 0

        while (not early_stopping) and (epoch &lt; n_epochs):
            total_loss = 0.0
            num_batches = 0
            self.model.train()
            for i, batch in enumerate(train_loader):
                num_batches += 1
                data = batch[&#39;data&#39;]
                labels = batch[&#39;target&#39;]

                # zero the parameter gradients
                self.optimizer.zero_grad()

                # forward + backward + optimize
                outputs = self.model(data)
                loss = criterion(outputs, labels)
                nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                loss.backward()
                self.optimizer.step()

                total_loss += loss.item()

            total_loss = round(total_loss / num_batches, 4)

            _, train_metrics = self._evaluate_model(
                train_loader, compute_loss=False)

            val_loss, val_metrics = self._evaluate_model(
                val_loader, compute_loss=True)

            train_metrics[&#39;loss&#39;] = total_loss
            val_metrics[&#39;loss&#39;] = val_loss

            for metric, value in train_metrics.items():
                train_history[metric].append(value)
            for metric, value in val_metrics.items():
                val_history[metric].append(value)

            with open(self.metadata.log_path, &#39;a&#39;) as f:
                f.write((f&#39;{datetime.datetime.now()}: Epoch {epoch+1}: &#39;
                         f&#39;TRAIN: {metrics_to_string(train_metrics)}\t&#39;
                         f&#39;VL:{metrics_to_string(val_metrics)}\n&#39;))

            val_f1 = val_metrics[&#39;f1&#39;]
            if val_f1 &gt; best_val_f1:
                best_val_f1 = val_f1
                waiting_epochs = 0
                best_epoch = epoch

                if val_f1 &gt; self.state_best_f1:
                    self.state_best_f1 = val_f1
                    chkpoint = CheckPoint(
                        self.model.state_dict(), train_metrics, val_metrics)
                    torch.save(chkpoint, open(
                        self.metadata.checkpoint_best_path, &#39;wb&#39;))
                    del chkpoint
                    with open(self.metadata.log_path, &#39;a&#39;) as f:
                        f.write((f&#39;{datetime.datetime.now()}: Epoch {epoch + 1}: &#39;
                                 f&#39;CHECKPOINT: Better Model Found\n&#39;
                                 ))

            else:
                waiting_epochs += 1
                if waiting_epochs &gt;= patience:
                    early_stopping = True
            if epoch % self.hyperparams.epoch2ckpt == 0:
                chkpoint = CheckPoint(
                    self.model.state_dict(), train_metrics, val_metrics)
                torch.save(chkpoint, open(
                    self.metadata.checkpoint_epoch_path, &#39;wb&#39;))
                del chkpoint

                with open(self.metadata.log_path, &#39;a&#39;) as f:
                    f.write((f&#39;{datetime.datetime.now()}: Epoch {epoch + 1}: &#39;
                             f&#39;CHECKPOINT: Passed &#39;
                             f&#39;{self.hyperparams.epoch2ckpt} epochs\n&#39;
                             ))

            epoch += 1

        if early_stopping:
            with open(self.metadata.log_path, &#39;a&#39;) as f:
                f.write((f&#39;{datetime.datetime.now()}: Epoch {epoch}: &#39;
                         f&#39;EARLY STOPPING\n&#39;
                         ))

        ckpt = torch.load(open(self.metadata.checkpoint_best_path, &#39;rb&#39;))
        result_model = ckpt.model

        if self.send_deltas:
            for key, value in initial_model_dict.items():
                result_model[key] = result_model[key] - value

        base_log_dir = os.path.dirname(self.metadata.log_path)
        for metric in [&#39;loss&#39;, &#39;precision&#39;, &#39;recall&#39;, &#39;f1&#39;]:
            pkl.dump(train_history[metric][:best_epoch+1],
                     file=open(f&#39;{base_log_dir}/{self.metadata.id}_train_{metric}_hist.pkl&#39;, &#39;wb&#39;))
            pkl.dump(val_history[metric][:best_epoch+1],
                     file=open(f&#39;{base_log_dir}/{self.metadata.id}_val_{metric}_hist.pkl&#39;, &#39;wb&#39;))
        # print(val_history[&#39;f1&#39;][:best_epoch+1])
        self.current_iteration += 1
        client_msg = ClientMessage(
            result_model,
            ckpt.train_metrics,
            ckpt.val_metrics,
            len(train_set),
            len(val_set),
            self._compute_support(train_set, server_message.target_label),
            self._compute_support(val_set, server_message.target_label))

        del ckpt
        train_metrics = client_msg.train_metrics
        val_metrics = client_msg.validation_metrics

        with open(self.metadata.log_path, &#39;a&#39;) as f:
            f.write((f&#39;{datetime.datetime.now()}: Ended Training: &#39;
                     f&#39;TRAIN: {metrics_to_string(train_metrics)}\t&#39;
                     f&#39;VL:{metrics_to_string(val_metrics)}\n\n&#39;))

        del self.model
        del self.optimizer
        if server_message.validation_msg.from_file:
            del train_set
            del val_set
        else:
            del self.dataset
        return [client_msg]

    def evaluate_metrics(self, server_message):
        &#34;&#34;&#34;
        ## Description:

        It performs the evaluation of the received model according to the predefined metrics. It eventually updates the internal state of the local client.

        ## Args:

        `server_message`: (ServerMessage)
        The message received from the parent node.

        ## Returns:

        ### [message: ClientMessage]

        A list with just one element. It stores the message which is transmitted to the parent node, made up of the model evaluation scores.

        &#34;&#34;&#34;
        self.model = self.hyperparams.build_model_fn()
        self.model.load_state_dict(server_message.new_model)
        batch_size = self.hyperparams.batch_size
        train_set, val_set = self._build_train_and_val_set(server_message)
        train_loader = create_data_loader(
            train_set, server_message.target_label, batch_size, shuffle=True)

        val_loader = create_data_loader(
            val_set, server_message.target_label, batch_size, shuffle=True)

        train_loss, train_metrics = self._evaluate_model(
            train_loader, compute_loss=True)

        val_loss, val_metrics = self._evaluate_model(
            val_loader, compute_loss=True)

        train_metrics[&#39;loss&#39;] = train_loss
        val_metrics[&#39;loss&#39;] = val_loss

        if val_metrics[&#39;f1&#39;] &gt; self.state_best_f1:
            self.state_best_f1 = val_metrics[&#39;f1&#39;]
            torch.save(server_message.new_model,
                       (self.metadata.checkpoint_best_path))

        with open(self.metadata.log_path, &#39;a&#39;) as f:
            f.write((f&#39;{datetime.datetime.now()}: Evaluating global model: &#39;
                     f&#39;TRAIN: {metrics_to_string(train_metrics)}\t&#39;
                     f&#39;VL:{metrics_to_string(val_metrics)}\n&#39;))

        client_msg = ClientMessage(
            server_message.new_model,
            train_metrics,
            val_metrics,
            len(train_set),
            len(val_set),
            self._compute_support(train_set, server_message.target_label),
            self._compute_support(val_set, server_message.target_label))

        return [client_msg]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="HOLDA.buildingBlocks" href="index.html">HOLDA.buildingBlocks</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>